\documentclass[12pt]{amsart}

\pagestyle{empty}
\textwidth 7.5in
\textheight 9in
\oddsidemargin -0.3in
\evensidemargin -0.2in
\topmargin -0.2in

\newcommand{\norm}[1]{\Vert #1 \Vert}
\newcommand{\Rn}{\R^n}
\newcommand{\Rm}{\R^m}
\newcommand{\R}{{\mathbb{R}}}
\newcommand{\grad}{\nabla}
\newcommand{\Rnn}{\R^{n\times n}}
\newcommand{\map}[3]{#1:#2\rightarrow #3}
\newcommand{\half}{\frac{1}{2}}
\newcommand{\Rmn}{\R^{m\times n}}
\newcommand{\tpose}[1]{#1^{\scriptscriptstyle T}}
\newcommand{\indicator}[2]{\delta\left(#1 \mid #2 \right)}


\usepackage{color}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\red}[1]{\textcolor{red}{#1}}


\newcommand{\prox}{\mathrm{prox}}
\newcommand{\logit}{\mathrm{logit}}


\usepackage{amsmath,epsfig,amssymb}
%\input{macros}
%\input{macros2}

\begin{document}
{\Large Name:}  John Min; jcm2199\\
\begin{center}
\Large COMS 4772 \hskip 2in Homework Set 3
\end{center}
\bigskip



\noindent

\begin{enumerate}

\item Two points on logistic regression

\begin{enumerate}

\item Bishop, ex. 4.14. Show that for a linearly separable data set, the maximum likelihood solution for the logistic regression model is obtained by 
finding a vector $w$ whose decision boundary $w^T \phi(x) = 0$ separates the classes, and then taking the magnitude of $w$ to infinity. 
{\it In optimization, a direction $w$ along which a function remains bounded is known as a direction of recession.}\\

$\displaystyle p(t|w) = \prod_{n=1}^{N} y_n^{t_n} (1-y_n)^{1-t_n} \\
p(C_1|\phi) = y(\phi) = \sigma(w^\top \phi) \\
p(C_2| \phi) = 1 - \sigma(w^\top \phi)$.

For $p(C_1 | \phi) = p(C_2 | \phi) = 0.5$, $\log \bigg( \frac{\sigma(w^\top \phi)}{1 - \sigma(w^\top \phi} \bigg) = 0 \Rightarrow \log(e^{w^\top \phi}) = 0 \Rightarrow w^\top \phi = 0.$ \\



\item Bishop, ex. 4.15, modified. Show that the Hessian matrix H for the logistic model, given by
\[
H = \sum_{n=1}^N y_n (1-y_n) \phi_n \phi_n^T
\]
is always positive semidefinite. What is a simple condition on the data that guarantees it is positive definite? \\

\noindent
Since $y_n \in \{0,1\}$, $y_n (1-y_n) \geq 0$.  The outerproduct, by definition, $\phi_n \phi_n^\top \geq 0$. \\
Thus, H is positive semi-definite.\\
If $0 < y_n < 1$, then, H would be positive definite. \\

\end{enumerate}


\item Fun with Neural Nets: please download Le Roux's code nnetLib from the class website. The main file, \verb{demo.m{, runs 
classification on the MNIST dataset (hand-written digits 0-9). The data file it uses, \verb{mnist_small.mat{, has 12000 examples, 
with feature length 784. The code splits these into training and testing, runs the training, and then evaluates the test error. 

There are several important switches: 
\begin{itemize}
\item \verb{params.Nh{ in line 13 controls the number of hidden nodes. 
\begin{itemize}
\item \verb{params.Nh = []{ (meaning `empty' in matlab) sets up the 10-class classification problem. 
\item \verb{params.Nh = 200{ sets up a neural net with one hidden layer of size 200. 
\item \verb{params.Nh = [100 100 100]{ sets up a neural net with three hidden layer of size 100. 
\end{itemize}
\item \verb{params.nIter{ controls the number of total iterations. 10 was set for demo; I changed it to 20. 
If you want to push the code with more layers, and larger layer sizes, you may want more iterations. 
\item \verb{params.cost{ in line 16 lets you pick the cost function to use, from $\{$mse, ce,  nll, class$\}$. \\
\end{itemize}

\begin{enumerate} 

\item Show that a neural network with no hidden layer reduces to the multinomial logistic classification model (this should be straightforward
using our notes). \\

\noindent
Softmax output\\


\item The three cost functions $\{$mse, ce,  nll$\}$ are options in the function \verb{computeCost.m{. 
The code processes the data in batches of size 20, and labels are given as elementary vectors of length 10. 
Therefore, both \verb{output{ and \verb{labels{ are always matrices 
of size $20\times10$. Only one entry in each row of \verb{labels{ is nonzero.\\

Given this information, study the code to write down formulas for the three objectives
in \verb{computeCost{. {\it My advice is to not think look at their names, but just to focus on the code. } \\

\noindent
Let $W$ be the weight decays cost, $\hat y$ be the  predicted output, $y$ label.\\

\begin{itemize}
\item MSE: $\displaystyle \frac{1}{2} \sum_{n=1}^N \big(y_n - \hat{y}_n \big)^2 + W$ \\

\item CE: $\displaystyle -\sum_{n=1}^N \Big[ y_n \hat{y}_n + \sigma\big(-\hat{y}_n\big) \Big]^2 + W$\

\item NLL: $\displaystyle \sum_{n=1}^N \bigg[-\log\Big( \sigma(\hat{y}_n)_j \Big) y_n \bigg] + W$\\

\end{itemize} 

\item Two of the three objectives should be familiar. What about the third? What is it trying to do? Do your best to give some intuition; 
you will get credit as long as you show you seriously considered it. \\


\item Numerical evaluations. The code uses stochastic gradient; I have therefore fixed the random seed (line 2 in \verb{demo.m{), to make sure 
you get the same output every time you run the code. Please do the following comparisons. Report each in a table. I made the tables for you,
you just have to fill them in. 

{\bf Whatever you decide for the iteration number (at least 20) please keep it the same for all experiments. 
This way we can at least compare all the methods by computational effort, since we will not know that we solved the optimization problem fully.} 

\begin{itemize}
\item Test errors for multinomial regression vs. 1-layer network with different hidden layer sizes, across three objective functions: \\

\begin{tabular}{|c|c|c|c|}\hline
 & MSE & CE & NLL \\ \hline
 \verb{params.Nh = []{ &21\%  &8.7\% &8.1\% \\ \hline
 \verb{params.Nh = 100{ &5.4 &  5.3  & 5.7\\ \hline
 \verb{params.Nh = 200{ &5.05& 4.75 & 5.5 \\ \hline
 \verb{params.Nh = 300{ &5.1 & 4.8 & 5.5 \\ \hline
\end{tabular} \\

\item Test errors for multiple layers of the same size, across three objective functions: \\

\begin{tabular}{|c|c|c|c|}\hline
 & MSE & CE & NLL \\ \hline
 \verb{params.Nh = 100{ &5.4\%&5.3\%&5.7\% \\ \hline
 \verb{params.Nh = [100 100] { &4.85& 4.85& 5.15 \\ \hline
 \verb{params.Nh = [100 100 100 ]{ &5.4&4.55&5.25 \\ \hline
  \verb{params.Nh = [100 100 100 100]{ &5.4& 4.45&4.95 \\ \hline
\end{tabular}\\

\item Summarize what you learned from the two experiments. Set up an experiment 
with your choice of layer size, layer number, and objective function, that beats the best test error you have seen so far, and report the error and the setup. Keep in mind the hidden layers don't need to be all the same size. \\
\end{itemize}

\noindent I have chosen the number of iterations to be 50.  There are two lessons to be learned.  The first is that optimizing for the different objective functions produce similar results.  Optimizing on cross-entropy (CE) seemed to produce the best test outcomes.The second is that adding more layers or increasing layer size on a neural network can lead to overfitting of the training data and thus, a bump in test error.  Finally, the final notion that must be considered is training time, which must be carefully traded-off with model performance.\\

\begin{tabular}{|c|c|}\hline
 & CE \\ \hline
 \verb{params.Nh = [50 50 50 50 50 50]{ &5.45\%\\ \hline
 \verb{params.Nh = [50 50 50 50 50 50 50]{ &5.45\\ \hline
 \verb{params.Nh = [50 100 100 100 100]{ &5.5\\ \hline
 \verb{params.Nh = [100 100 100 100 100]{ &\textbf{3.9}\\ \hline
 \verb{params.Nh = [100 100 100 100 100 100]{ &\textbf{3.95}\\ \hline
 \verb{params.Nh = [100 200] { &4.9\\ \hline
 \verb{params.Nh = [100 300] { &4.9\\ \hline
 \verb{params.Nh = [200 200]{ &4.5 \\ \hline
 \verb{params.Nh = [200 200 100 100]{ &\textbf{4.1} \\ \hline
 \verb{params.Nh = [200 300]{ &\textbf{3.95} \\ \hline
 \verb{params.Nh = [200 300 100 100]{ &4.3 \\ \hline
 \verb{params.Nh = [200 400]{ &4.4\\ \hline
  \verb{params.Nh = [300 300]{ &4.45\\ \hline
  \verb{params.Nh = [300 200]{ &4.55\\ \hline
\end{tabular}\\


\end{enumerate}

\newpage 
\item Bonus. Modify the \verb{demo{ file to contaminate a portion of your training data, 
by flipping a percentage of the labels. 

\begin{enumerate}
\item Evaluate the effect of proportion of flipped labels on the testing error: \\

\begin{tabular}{|c|c|c|c|}\hline
 & MSE & CE & NLL \\ \hline
 \verb{params.Nh = [], 0% contaminated { &21\%  &8.7\% &8.1\% \\ \hline
  \verb{params.Nh = [], 1% contaminated{  &20.6 & 8.95& 8.4 \\ \hline
 \verb{params.Nh = [], 5% contaminated{  & 20.95& 9.4 & 10.05\\ \hline
  \verb{params.Nh = [], 10% contaminated{  & 21.05 & 10.6& 9.95 \\ \hline
  \verb{params.Nh = [], 25% contaminated{  &20.9 & 12.2 & 11.65 \\ \hline
 \verb{params.Nh = 100, 0% contaminated{ &5.4 &  5.3  & 5.7\\ \hline
  \verb{params.Nh = 100, 1% contaminated{  &5.9 &5.55 & 5.3\\ \hline
 \verb{params.Nh = 100, 5% contaminated{  &5.5 & 5.1& 5.4\\ \hline
  \verb{params.Nh = 100, 10% contaminated{  &5.85 &6.3 &5.85 \\ \hline
  \verb{params.Nh = 100, 25% contaminated{  &6.25 &7.1 & 7.15\\ \hline
\end{tabular} \\

\item Add two robust options to the \verb{computeCost.m{ file (analogous to MSE), one using the Huber function, and one using the Student's t log-likelihood: \\
\[
f(r) = \sum \ln(\nu + r_i^2)
\]\\

\item Compare your robustified versions on the experiment you developed: \\

\begin{tabular}{|c|c|c|c|}\hline
 & MSE & huber MSE & student MSE \\ \hline
 \verb{params.Nh = [], 0% contaminated{  21 \%&21.5\% & & \\ \hline
  \verb{params.Nh = [], 1% contaminated{  & & & \\ \hline
 \verb{params.Nh = [], 5% contaminated{  & & & \\ \hline
  \verb{params.Nh = [], 10% contaminated{  & & & \\ \hline
 \verb{params.Nh = [], 25% contaminated{  & & & \\ \hline 
 \verb{params.Nh = 100, 0% contaminated{  &5.4 & 6.15& \\ \hline
  \verb{params.Nh = 100, 1% contaminated{  & & & \\ \hline
 \verb{params.Nh = 100, 5% contaminated{  & & & \\ \hline
  \verb{params.Nh = 100, 10% contaminated{  & & & \\ \hline
  \verb{params.Nh = 100, 25% contaminated{  & & & \\ \hline
\end{tabular}\\\\
 

\item Did the robust measures help? How did they fare compared to the ML estimators for contaminated data? 

\end{enumerate}




\end{enumerate}


\end{document}
